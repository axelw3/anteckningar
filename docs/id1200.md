# ID1200 Operativsystem 6,0 hp
|Tillfälleskod|Termin(er)|Period(er)|Föreläsare|
|-|-|-|-|
|51093|HT2025|1-2|Ivy Bo Peng|

Anteckningar med utgångspunkt i föreläsningsslides.

## M0: Föreläsning 1
### Historia
> * 1945-1955: Före operativsystem. Datorer programmerades genom omkoppling.
> * 1955-1965: Programmering med hålkort. En operatör laddar sedan program på ett magnetiskt band, och kör sedan ett speciellt program (monitor) som exekverar önskade program sekventiellt.
> * 1965-1980: Multiprogrammerade batch-system. Flera jobb hålls i datorns minne samtidigt och varje jobb hålls körande tills ex.vis I/O (blockerande) anropas. Senare uppkommer tidsdelning (UNIX).
> * 1980-nu: Persondatorer. Övergång från mänskliga operatörer till mjukvara (*operativsystem*).

### Operativsystem
> Ett operativsystem är ett program som agerar mellanhand mellan användare/program och hårdvaran.
> 
> Operativsystemet *allokerar resurser* och *förhindrar fel*.

Syfte:

1. Isolerade program.
2. Förenkla utveckling.
3. Nyttja hårdvara effektivt.

### Multiprogrammering
Schemalägger *processorer* för att maximera hålla processorn sysselsatt. När någon process väntar på ex.vis I/O, byter operativsystemet till en annan process.

### Arkitekturer
* Enprocessorsystem
* Flerprocessorsystem (flera kärnor och/eller CPUer)
* Kluster

### Multitasking, time slicing
Processorn byter fokus regelbundet, så att varje process får körtid.

Om flera processer är redo att köras, krävs CPU-schemaläggning för att välja en av dessa.

### Delar i ett operativsystem
#### Processhantering
* Schemaläggning av processer och trådar
* Skapa och avsluta processer på användar- och systemnivå
* Pausa (*suspending*) processer
* Synkronisering
* Inter-processkommunikation (IPC)

#### Minneshantering
För att köra ett program krävs att både *instruktioner* och *data* finns i minnet.

Mål: Optimera CPU-användning och svarstider genom att placera data och instruktioner i main memory.

Hanterar även allokering och avallokering av minne.

#### Enhetshantering och I/O-subsystem
Hanterar och väljer drivrutiner för olika enheter. Drivrutinerna översätter i sin tur operativsystemets instruktioner till enhetsspecifika instruktioner.

En device controller hanterar interrupts.

Huvudsakliga I/O-subsystem i kerneln:

* I/O-schemaläggning
* Buffring och cachning
* Felhantering: t.ex. buffer-overflow, diskcrash, minnesfel
* I/O-säkerhet

## M1: Föreläsning 2
### Processer
En *process* är ett program i exekvering. Programkoden är en "passiv entitet", medan processen är motsvarande "aktiva entitet".

#### Programmets delar
* **Text**: Körbar kod (maskinkod).
* **Data**: Globala variabler.
* **Heap**: Dynamiskt allokerat minne.
* **Stack**: Funktionsparametrar, lokala variabler, etc. (dvs. temporär data).

#### Representation i operativsystemet
För varje process lagras ett *Process Control Block* (PCB) - en datastruktur som innehåller:

* Tillstånd
* Nummer (PID)
* Programräknare
* Registervärden
* Minnesomfång
* Lista över öppna filer

I Linux används en dubbellänkad lista dessa i form av en dubbellänkad lista.

#### Processtillstånd
* **New**: Processen skapas...
* **Ready**: Processen väntar på att tilldelas en processor.
* **Running:** Instruktioner utfärdas.
* **Waiting:** Väntar på ex.vis slutförd I/O-åtgärd
* **Terminated:** Processen har avslutats.

#### Schemaläggning
$$\text{CPU Util.}=\frac{\text{aktiv tid}}{\text{total tid}}$$

Viktigt om antal processer större än antal kärnor!

*Multiprogrammering* innebär att flera processer finns i minne samtidigt. När någon process väntar på en I/O-operation, skiftar kerneln exekvering till en annan process.

Finns olika sätt att uppnå detta:

* *Preemptive multitasking*: Tidsgräns avgör.
* *Cooperative multitasking*: Processer avstår frivilligt tid.

##### Köer
* Ready queue: Innehåller processer i tillstånd "Ready".
* Wait queue: Innehåller processer i tillstånd "Waiting"

###### Schemaläggningspolicyer
* First come, first serve (FCFS)
* Round robin (RR)
* Shortest Job First (SJF)

#### Kontextbyte
Grunden för multiprogrammering är *kontextbyten* - då en processor byter process. Kerneln sparar då den aktuella processens tillstånd i dess PCB och tillståndet återställs från den nya processens PCB.

Viktigt att minimera tidsåtgång: hårdvaruacceleration samt färre kontextbyten.

#### Processkapande med `fork()`
* Barnet ges en *kopia* av förälderns minnesområde.
* Två returvärden: för föräldern `<barnets PID>` och för barnet `0`.
* Barnet exekverar kod omedelbart efter `fork()`-anropet.
    * Ett `exec()`-anrop kan användas för att istället köra ett givet program.

> **Alternativ: `clone()`**
> 
> Erbjuder mer kontroll över vad som delas mellan barn och förälder. Exempelvis
> adress för stack samt instruktioner (funktionspekare) kan ges uttryckligen.

* *Zombie*: Ett barn som har terminerat, men vars förälder inte ännu anropat `wait()`.
* *Orphan*: Ett barn vars förälder terminerat utan att anropa `wait()`.
    * init-processen blir ny förälder åt dessa.

### Interprocess-kommunikation (IPC)
Två modeller:

* Delat minne
* Meddelanden
    * Dataström
        * Pipe
        * FIFO (namngiven pipe)
    * Meddelandeström/meddelandekö

#### Delat minne
* `shm_open()`: Skapa och öppna ett delat minnesobjekt.
* `mmap()`: Skapa en ny översättning i det virtuella adressutrymmet.
* `shm_unlink()`: Ta bort ett delat minnesobjekt.

#### Pipe
* En speeciell sorts fil - använder `read()`/`write()`.
* Enkelriktad - den ej använda riktningen måste stängas!
* Raderas automatiskt när samtliga file descriptors har stängts.

#### Namngiven pipe (FIFO)
* Kan vara dubbelriktad samt användas av flera processer.
* Skapas med systemanropet `mkfifo()`.
* *Implicit synkronisering* - läsning blockerar tills någon annan process skriver.

#### Meddelandekö
* Strukturerade meddelanden med olika prioritet.
* Ingen synkronisering - meddelanden stannar i kön tills de läses.

## M1: Föreläsning 3
### Utilities
* `strace` - Spåra systemanrop.
* `vmstat <delay>` - Processer, minne, paging, blockerande I/O, traps, diskar och processoranvändning.
* `pidstat -w -p <pid>` - Statistik för enskilda processer sedan uppstart.
* `ps` - Information om processer.

### Trådar
* Trådar *delar* kod, data-avsnitt samt filer.
    * Separat: tråd-ID, programräknare, register och stack.
    * Snabb start.
    * Lägre minnesanvändning!
    * Trådbyte snabbare än kontextbyte.
* Enklare och snabbare kommunikation.

* Flertrådad programmering förbättrar *samtidighet* (concurrency).
    * Samtidighet: Flera pågående åtgärder samtidigt, men ej nödvändigtvis parallellt.
    * Parallellism: Flera åtgärder utförs på *en och samma gång*, parallellt.
        * Data-parallellism (DLP): Fördela indata mellan kärnor.
        * Uppgiftsparallellism (TLP): Fördela uppgifter/trådar mellan kärnor.

#### User-trådar och kernel-trådar
* User-trådar: Hanteras av trådbibliotek på user-nivå. Exempel: POSIX pthreads.
* Kernel-trådar: Används av moderna operativsystem att förbättra effektivitet direkt i kerneln.

##### Flertrådningsmodeller
User-trådar behöver tilldelas motsvarande kerneltrådar.

* Many-to-one: En blockerande tråd gör att övriga user-trådar blockeras.
    * Endast en tråd kan vara i kerneln i taget.
* One-to-one (Win & Linux): Varje user-tråd tilldelas en kernel-tråd.
    * Ökad samtidighet jämfört med many-to-one.
    * Antalet trådar per process ibland begränsat för att minska omkostnader.
* Many-to-many

### Trådhantering
* Ett trådbibliotek kan antingen köras helt i userspace, eller genom OS-stöd operera på kernelnivå.

#### Pthread
* Ett POSIX-api på user- OCH kernel-nivå.
* Trådar skapas med `pthread_create()`.
* Tråd-id fås av `pthread_self()`.
* Terminera med `pthread_exit()` (själv) eller `pthread_cancel()` (från annan tråd).
* Vänta på annan tråd med `pthread_join()`, eller frånkoppla med `pthread_detach()`.

> **Avbryt tråd:** Två tillvägagångssätt (välj med `pthread_setcanceltype()`).
> 
> * `PTHREAD_CANCEL_ASYNCHRONOUS`: Omedelbart.
> * `PTHREAD_CANCEL_DEFERRED`: Trådfunktionen avbryts vid nästa "cancelation point" (definieras av POSIX.1).

### Implicit trådning
* *Implicit trådning*: Trådar skapas och hanteras av kompilator eller vid körtid.
* *Trådpool*: En mängd trådar som kan tilldelas uppgifter vid behov.

* OpenMP: Kompilatordirektiv för att identifiera parallella regioner. T.ex. `#pragma omp parallel`.

### Trådproblem & egenskaper
* `fork()` skapar en process med en tråd, som är en kopia av anropande tråd.

#### Signalhantering
* En signal mottas från operativsystemet vid en särskilt händelse, t.ex. `SIGINT`.
* *Synkrona signaler* levereras till processen som orsakade signalen.
* *Asynkrona signaler* genereras av en extern händelse, t.ex. nedtryckt tangent.
* Varje signal *måste* hanteras. Detta sköts av en signalhanterare.

* Flertrådade processer: Signaler levereras till berörd tråd, till alla trådar, till vissa trådar, eller till en utsedd mottagare.
* Processer och trådar kan blockera vissa signaler med `sigprocmask()` resp. `pthread_sigmask()`.

#### Trådlokal lagring (TLS)
* TLS låter varje tråd ha en egen kopia av data.
* Användart när kontroll över trådskapande saknas (t.ex. trådpool).
* Ej att förväxla med lokala variabler.

## M2: Föreläsning 4
* Målet med multiprogrammering är att *maximera CPU-utilisering*.

### CPU-schemaläggning
**CPU I/O burst cycle**: Processers exekvering består av periodvis CPU-exekvering och I/O-väntan.

**CPU-schemaläggaren** väljer en process ur *redo-kön* att allokera CPU:n till.

Sådana val görs när en process övergår till redo-tillståndet, men *behöver inte* göras när tillståndet växlar till *waiting* (t.ex. I/O-burst inleds) eller *terminated*.

* Scheduler: Tar beslut
* Disptacher: Byter kontext, övergår till user mode och uppdaterar programräknaren.
    * *Dispatch latency*: Tidsluckan mellan två processers exekvering.

#### Preemptive vs icke-preemptive schemaläggning
* Icke-preemptive: Processer allokeras CPU-fokus tills terminering eller waiting-tillstånd.
* Preemptive: Även ex.vis interrupts (running --> ready) eller I/O-slutföranden (waiting --> ready).

Egenskaper hos en schemaläggning:

* CPU-utilisering
* Throughput: Antal slutförda processer per åtgången tid (makespan = från början av första exekvering till slutförande av sista).
    * Långa processer ==> lägre throughput
* Turnaround time: Tidsåtgång för en specifik process.
    * $T_\text{turnaround}=T_\text{completion}-T_\text{arrival}$
* Väntetid: Tid som en specifik process spenderat i ready-kön.
* Svarstid: Tid från processens skapelse till första utdata.

#### Schemaläggningsalgoritmer
* First-come, first-serve (FCFS)
    * Convoy effect: Många processer kan behöva vänta på en stor att slutföras. *Genomslittlig väntetid* blir då högre.
* Shortest-job-first (SJF)
    * Avgörs av längden hos nästa CPU-burst.
    * Ger minsta möjliga genomsnittliga väntetid för en given mängd processer.
    * Problem: Total tidsåtgång okänd. Nästa I/O-burst inte alltid förutsägbar.
    * Vanligtvis prognostisering med *exponentiellt genomsnitt*: $\tau_{n+1}=\alpha\cdot t_n+(1-\alpha)\cdot\tau_n$
        * $\tau_n,\tau_{n+1}$: förutspådd tidpunkt för senaste/nästa burst
        * $t_n$: verklig tid för senaste burst
        * $\alpha$: en viktparameter $0\leq\alpha\leq 1$.
    * Preemptive: kallas då för *shortest-**remaining-time**-first*.
* Round-robin
    * Tidsfönster $q$ för varje process - därefter nästa.
    * Ready-kö kan implementeras som en cirkulär buffer.
* Priority scheduling
    * CPU allokeras alltid till processen med högst prioritet.
    * Problem: starvation (processer med låg prioritet får ingen processortid!)
        * Lösning: aging (prioritet ökar)
* Multilevel queue: flera ready-köer med olika policyer

### Schemaläggning: implementation
* Linux: *Completely Fair Scheduler* (CFS)
    * *Nice*-värde: Lägre värde = större andel av CPU-tid

#### Trådar - Contention scope
* User-level threads: Hanteras av trådbibliotek, utan direkt inblandning från OS-kerneln.
    * Process-contention scope (PCS): Konkurrens internt mellan trådar i processer.
* Kernel-level threads: Schemaläggs av operativsystemet.
    * System-contention scope (SCS) (1-1-modell): Konkurrens mellan alla systemets trådar.

Val av scope görs med `pthread_attr_setscope()`: `PTHREAD_SCOPE_PROCESS` (PCS) eller `PTHREAD_SCOPE_SYSTEM` (SCS).

#### Multiprocessorer
* Asymmetrisk multiprocessering: Endast en processor ansvarar för schemaläggning, I/O-hantering och andra systemåtgärder.
    * Övriga exekverar bara användarkod.
* Symmetrisk multiprocessering (SMP): Varje processor schemalägger sitt eget arbete.
    * Gemensam eller individuell ready-kö.

* *Varmt cache*: Data nyligen använd av en tråd behålls i cache.
* Om en tråd flyttas till en annan processor - cache i #1 ogiltigmarkeras & cache i #2 återbyggs.

##### Processoraffinitet
*Processoraffinitet* innebär att en process stannar på samma processor.

* Hård affinitet: Varje process väljer tillåtna processorer.

##### Multi-NUMA
* NUMA: non-uniform memory access
    * Lokal minnesåtkomst snabbare än åtkomst till minne på annan NUMA-nod.

## M2: Föreläsning 5
### Synkronisering
P.g.a. risk för *data races* krävs synkronisering vid delning av data.

*Kritiskt avsnitt*: Kodavsnitt där endast en process/tråd tillåts befinna sig åt gången.

#### Petersons lösning
Enkel lösning. Förutsätter endast två processer.

> Problem: Moderna kompilatorer riskerar omordna instruktionerna, eftersom databeroenden saknas.

#### Hårdvarustöd
Beroende på minnesmodell speglas minnesuppdateringar på övriga processorer/kärnor olika snabbt.

* Strongly ordered: Omedelbart synligt.
* Weakly ordered: Så småningom synligt.

##### Minnesbarriärer
* Kompilator-baserat: Instruerar kompilatorn att ej låta minnesåtkomster omordnas kontra barriären.
* Hårdvaru-baserat: T.ex. `MFENCE` (Intel x86)

##### Atomiska instruktioner
* Compare-and-swap (CAS): "Skriv ett värde `x` till en minnesadress `y` endast om nuvarande värde är `z`."
    * Kan användas för att implementera ett lås.

## M2: Föreläsning 6
### Synkronisering, forts.
#### Mutex
* Atomiska aquire/release-funktioner.
* Implementation: Spinlock (aquire-funktionen loopar tills den lyckas) att föredra på flerkärnade system -- undviker dyra kontextbyten.

#### Semafor
* Ett icke-negativt heltal $S$ och två atomiska operationer:
    * `wait()` minskar $S$ så fort som möjligt
    * `signal()` ökar $S$
    * Binär semafor: Endast värden 0 och 1 tillåts.

### Liveness
* Ett system bör säkerställa liveness (= avsaknad av *starvation*).
    * Alla processer/trådar gör framsteg.
* Deadlock: Varje process väntar på händelse som bara kan orsakas av en annan process.
    * 4 villkor:
        * Mutual exclusion: Minst en icke-delbar resurs.
        * Hold-and-wait: En tråd/process har erhållit en resurs samt väntar på en annan.
        * Resurser återlämnas inte automatiskt.
        * Cirkulär väntan: $T_0$ väntar på resurs erhållen av $T_1$, $T_1$ väntar på (....) $T_0$
* Livelock: Processer ändrar tillstånd upprepade gånger utan att framsteg görs.

### Priority inversion
Om en process med hög prioritet väntar på en med låg prioritet kan ett deadlock uppstå.

* Priority inheritance protocol: Beroenden erhåller samma höga prioritet tills deras användning av den delade resursen slutförts.

### Resursallokeringsgrafer
Graf med noder T (trådar) och R (resurstyper).

Kanter:

* Förfrågan: Riktad kant från någon T (tråd) till någon R (resurstyp).
* Tilldelning: Riktad kant från någon *specifik resurs* till någon T (tråd).

Cykel finns ==> möjlig deadlock

Frågan är då: *Går det att bryta cykeln?*

## M2: Föreläsning 6.2
### Förhindra deadlocks
Tumregel: Identifiera och eliminera deadlock-faktorer.

* Mutual exclusion (mutex)
    * Lösning: Kringgå behov av mutex genom att endast använda delade resurser (sällan praktiskt möjligt).
* Säkerställ att hold-and-wait-tillstånd aldrig uppstår.
    * Säkerställ att trådar inte allokeras resurser före väntan på annan resurs.
    * Lösning: trådar får endast begära resurser om den inte redan allokerats någon
    * Lösning 2: kräv att processer begär och allokerar alla resurser före exekvering
* Frigör resurser (preemption) för processer vid väntan på annan resurser
    * För processer som begär ej tillgängliga resurser:
        * Släpp alla resurser och preempta processen.
        * Vänta på att alla resurser är tillgängliga.
        * Fördel: Enkelt att implementera för enkla allokeringar.
* Bryt cirkulärt resursberoende:
    * I praktiken: Trådar begär resurser endast i stigande nummerordning.
    * Gör en totalordning av alla resurstyper

### Undvik deadlocks
* Identifiera *säkra tillstånd* - där deadlock inte är möjligt.
* Ett sätt att definiera ett säkert tillstånd:
    * "Ingen process kräver fler resurser än de som finns tillgängliga"
* Deadlock avoidance = förhindra osäkra tillstånd!

* Varje gång en process begär en tillgänglig resurs: avgör om omedelbar allokering orsakar ett osäkert tillstånd.

> **Exempel:** Anta att ett system har 12 resursinstanser.
> 
> |Process|Maximalt krävda|Aktuella allokeringar|
> |-|-|-|
> |P1|10|5|
> |P2|4|2|
> |P3|9|2
>
> Initialt är vi i ett säkert tillstånd. Därefter är sekvensen P2, P1, P3 säker.

#### Algoritmer för deadlock avoidance
* Resursallokeringsgrafer
    * Claim edge (P->R, streckad linje): "Processen *kan* behöva resursen"
    * Vid förfrågan: *Claim edge* blir en *request edge*.
    * Vid användning: *Request edge* blir *assignment edge*.
    * Behov upphör: *Assignment edge* återgår till en *claim edge*.
    * Obs! Resurser måste reserveras *a priori*.
    * Hantering av begäran:
        * **Tillåt** *endast om* konvertering av request-kanten till assignment-edge inte resulterar i en cykel.
            * Notera: Claim-kanter behöver tas i hänsyn.
* Banker's algoritm
    * Observera! Varje process måste, *a priori*, ange maximalt antal använda instanser för varje resurstyp.
    * När en process erhållit alla sina resurser, måste de släppas inom en begränsad tid.

### Detektera deadlock
* Wait-for-graf (krav: resurser med endast en instans)
    * Kant från $P_i\leftarrow P_j$ omm $P_i$ kommer behöva vänta på $P_j$.
    * Om cykel finns -- deadlock!

### Deadlock-lösning
* Avbryt processer/trådar
    * Alla låsta
    * En i taget tills deadlock löses
* Frigör resurser tills deadlock löses
    * Ge resurser till andra processer

## M3: Föreläsning 7
### Swapping
* En process kan *swappas ut* tillfälligt -- data i minnet flyttas till disk.

### Minneshierarki
* Register (1 klockcykel)
* L2/L3 cache (ca 4-10 cykler)
* Main memory (100-tals cykler)

### Logisk/fysisk adressrymd
* *Logisk (virtuell) adress*: Används av CPU.
* *Fysisk adress*: Används av minnesenhet.
* MMU översätter logiska adresser till fysiska (vid körtid).
    * *Fysisk adress* = *virtuell adress* + *relocation register*.

### Minnesskydd
* Separat minnesrymd för varje process.
* Två *relocation registers* ("base" & "limit") tillåten virtuell adressrymden för processen.
* Kollas steget före MMU.

### Adressbindning
* Ett körbart program innehåller endast *symboliska* minnesadresser.
* Adressbindning innebär att de symboliska adresserna översätts till virtuella adresser.
    * Vanligast är att (vid kompilering) generera *relocatable code* & sedan (vid inläsning) beräkna absoluta adresser.
* Statisk länkning: Systembibliotek och programkod sammanfogas i den genererade binärfilen.
* Dynamisk länkning: Länkning sker vid körtid.
* Dynamisk inläsning: Biblioteksrutiner läses inte in förrän de anropas.
    * Fördel: Ej använda rutiner upptar ej minne.

### Allokering
* Flerpartitionsallokering: Minne delas in i partitioner.
    * Varje partition innehåller exakt en process.
    * När en partition är fri, väljs en process från input-kön och dess data läses in.
    * Bestämd eller variabel storlek
        * Variabel storlek: När data skall hämtas för en process, allokeras minne från ett tillräckligt stort "hål". När en process avslutas sammanfogas angränsande fria partitioner.
            * Olika scheman:
                * First fit: Välj det *första* hålet som är tillräckligt stort.
                * Best fit: Väljs det *minsta* hålet som är tillräckligt stort.
                * Worst fit: Välj det *största* hålet, totalt.

### Minnesfragmentering
* Extern fragmentering: Minne finns, men det är ej sammanhängande.
    * Lösning: *compaction* (flytta innehåll för att skapa ett större sammanhängande block)
    * Lösning 2: Tillåt virtuella adressrymder som inte är sammanhängande.
        * Exempel: *paging*
* Intern fragmentering: Allokerat minne är lite större än efterfrågat.
    * Paging kan ej helt undvika intern fragmentering.

## M3: Föreläsning 8
### Paging
* *Virtuellt* minne delas upp i *pages* av bestämd storlek.
* *Fysiskt* minne delas upp i *frames* av samma storlek.
* Operativsystemet håller koll på alla *lediga frames*.
    * Vid programstart allokeras tillräckligt många frames.
    * Därefter sparas minnesadresser i en *page-tabell* (virtuell --> fysisk adress).
    * Processer får en *sammanhängande* virtuell adressrymd, men motsvarande *pages* är utspridda i det fysiska minnet.

*Intern fragmentering* ett problem: $\text{fragmenterings-kvot}=\frac{\text{allokerat}-\text{efterfrågat}}{\text{allokerat}}$

I genomsnitt motsvarar fragmenteringen &half; sidstorlek. Liten sidstorlek minskar därför (intern) fragmentering. *Kräver dock större page-tabell!*

#### Adressöversättning
* Logiska adresser ($m$ bitar) består av två delar:
    * $m-n$ bitar: Page-nummer.
    * $n$ bitar: Page-offset.

### Paging-hårdvara
* Page-tabellen sparas i fysiskt minne.
* En page anses *giltig* (= finns i fysiskt minne) endast om present-biten är satt till 1.
* Transition look-aside buffer (TLB): En slags *cache* för adressöversättning.

### Utökade page-tabeller
#### Hierarkiska page-tabeller
* Flera nivåer av page-tabeller. Varje "yttre" sida består av en "inre" page-tabell.

#### Hashade page-tabeller
* Hierarkiska page-tabeller komplicerade & ineffektiva vid större adressrymd.
* Virtuellt sidnummer = hash-värde
* Varje element i hash-tabellen innehåller en länkad lista av VPN + page frame.

##### Klustrade page-tabeller
* Varje element i page-tabellen innehåller ett kluster av PTE:er.

#### Inverterade page-tabeller
* Hierarkiska och hashade page-tabeller sakpas för varje process.
    * Nackdel: Hög minnesförbrukning.
* Som alternativ till detta finns *inverterade page-tabeller*.
    * Dessa består av en rad för varje frame i fysiska minnet.
    * Varje rad består av &lt;PID&gt; & &lt;page-nummer&gt;.
    * Det räcker då med enda page-tabell! Denna har en rad för varje page i det fysiska minnet!
    * Fördel: Minskad minnesförbrukning.
    * Nackdel: Ökad tidsåtgång för uppslag.

## M3: Föreläsning 9
TODO

## Modul 4: I/O-subsystem och filsystem
### Föreläsning 10
### Föreläsning 11
### Föreläsning 12
### Föreläsning 13